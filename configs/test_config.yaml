models:
  normal:
    api_base: "http://localhost:8001/v1"
    model: "gpt-3.5-turbo"
    default_params:
      temperature: 0.7
      max_tokens: 1000
  reasoner:
    api_base: "http://localhost:8002/v1"
    model: "gpt-4"
    disabled_params:
      - temperature
      - presence_penalty
      - frequency_penalty

prompts:
  pre_process: |
    You are a preprocessing agent. 
    Analyze the following user input and structure it:
    ${input}

  reasoning: |
    You are a reasoning agent.
    Break down the problem and solve it step by step:
    ${input}

  post_process: |
    You are a postprocessing agent.
    Based on the reasoning chain and intermediate results,
    generate a clear and concise response:
    Reasoning: ${reasoning_chain}
    Result: ${intermediate_result}
